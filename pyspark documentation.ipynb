{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext \n",
    "from pyspark import SQLContext\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.7.29:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>First Lesson</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=First Lesson>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(appName ='First Lesson', master = 'local')\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('file:///Users/tjmask/Desktop/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USE db_countries;', '-- IMPORTING DATA FROM A CSV']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuc(lines):\n",
    "    lines =lines.lower()\n",
    "    lines = lines.split()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = rdd.map(fuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['use', 'db_countries;'], ['--', 'importing', 'data', 'from', 'a', 'csv']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use', 'db_countries;', '--', 'importing', 'data']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd.flatMap(fuc)\n",
    "rdd2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['db_countries;', '--']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=['a', 'use', 'the', 'is']\n",
    "rdd3 = rdd2.filter(lambda x: x not in stopwords)\n",
    "rdd3.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('db_', <pyspark.resultiterable.ResultIterable at 0x114eb5fd0>),\n",
       " ('--', <pyspark.resultiterable.ResultIterable at 0x114eb5f90>),\n",
       " ('imp', <pyspark.resultiterable.ResultIterable at 0x114eb9250>),\n",
       " ('dat', <pyspark.resultiterable.ResultIterable at 0x114eb90d0>),\n",
       " ('fro', <pyspark.resultiterable.ResultIterable at 0x114eb93d0>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4 = rdd3.groupBy(lambda x: x[0:3])\n",
    "rdd4.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('db_', ['db_countries;']), ('--', ['--', '--', '--']), ('imp', ['importing']), ('dat', ['data']), ('fro', ['from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from', 'from'])]\n"
     ]
    }
   ],
   "source": [
    "print([(k,list(v)) for (k, v) in rdd4.take(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd = sc.parallelize(range(1,5))\n",
    "num_rdd.reduce(lambda x,y: x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x114e7c990>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sparkconf\n",
    "import pyspark\n",
    "rmowers = sqlContext.read.csv('file:///Users/tjmask/Desktop/Semester2/Spark/PySpark/Datasets/RidingMowers.csv', \\\n",
    "                              inferSchema='true', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+\n",
      "|Income|Lot_Size|Ownership|\n",
      "+------+--------+---------+\n",
      "|  60.0|    18.4|    Owner|\n",
      "|  85.5|    16.8|    Owner|\n",
      "|  64.8|    21.6|    Owner|\n",
      "|  61.5|    20.8|    Owner|\n",
      "|  87.0|    23.6|    Owner|\n",
      "| 110.1|    19.2|    Owner|\n",
      "| 108.0|    17.6|    Owner|\n",
      "|  82.8|    22.4|    Owner|\n",
      "|  69.0|    20.0|    Owner|\n",
      "|  93.0|    20.8|    Owner|\n",
      "|  51.0|    22.0|    Owner|\n",
      "|  81.0|    20.0|    Owner|\n",
      "|  75.0|    19.6| Nonowner|\n",
      "|  52.8|    20.8| Nonowner|\n",
      "|  64.8|    17.2| Nonowner|\n",
      "|  43.2|    20.4| Nonowner|\n",
      "|  84.0|    17.6| Nonowner|\n",
      "|  49.2|    17.6| Nonowner|\n",
      "|  59.4|    16.0| Nonowner|\n",
      "|  66.0|    18.4| Nonowner|\n",
      "+------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmowers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Income: double (nullable = true)\n",
      " |-- Lot_Size: double (nullable = true)\n",
      " |-- Ownership: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmowers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmowers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|Income|Ownership|\n",
      "+------+---------+\n",
      "|  60.0|    Owner|\n",
      "|  85.5|    Owner|\n",
      "|  64.8|    Owner|\n",
      "|  61.5|    Owner|\n",
      "|  87.0|    Owner|\n",
      "| 110.1|    Owner|\n",
      "| 108.0|    Owner|\n",
      "|  82.8|    Owner|\n",
      "|  69.0|    Owner|\n",
      "|  93.0|    Owner|\n",
      "|  51.0|    Owner|\n",
      "|  81.0|    Owner|\n",
      "|  75.0| Nonowner|\n",
      "|  52.8| Nonowner|\n",
      "|  64.8| Nonowner|\n",
      "|  43.2| Nonowner|\n",
      "|  84.0| Nonowner|\n",
      "|  49.2| Nonowner|\n",
      "|  59.4| Nonowner|\n",
      "|  66.0| Nonowner|\n",
      "+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmowers.select('Income', 'Ownership').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Income|\n",
      "+-------+------------------+\n",
      "|  count|                24|\n",
      "|   mean|           68.4375|\n",
      "| stddev|19.793143575710648|\n",
      "|    min|              33.0|\n",
      "|    max|             110.1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmowers.describe('Income').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+\n",
      "|Income|Lot_Size|Ownership|\n",
      "+------+--------+---------+\n",
      "| 110.1|    19.2|    Owner|\n",
      "| 108.0|    17.6|    Owner|\n",
      "|  93.0|    20.8|    Owner|\n",
      "+------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmowers.filter(rmowers.Income >= '90').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+\n",
      "|Income|Lot_Size|Ownership|\n",
      "+------+--------+---------+\n",
      "|  60.0|    18.4|    Owner|\n",
      "|  85.5|    16.8|    Owner|\n",
      "|  64.8|    21.6|    Owner|\n",
      "|  61.5|    20.8|    Owner|\n",
      "|  87.0|    23.6|    Owner|\n",
      "| 110.1|    19.2|    Owner|\n",
      "| 108.0|    17.6|    Owner|\n",
      "|  82.8|    22.4|    Owner|\n",
      "|  69.0|    20.0|    Owner|\n",
      "|  93.0|    20.8|    Owner|\n",
      "|  81.0|    20.0|    Owner|\n",
      "+------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmowers.where((rmowers.Income >= 60) & (rmowers.Ownership=='Owner')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmowers.registerTempTable('rmowers_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+\n",
      "|Income|Lot_Size|Ownership|\n",
      "+------+--------+---------+\n",
      "|  60.0|    18.4|    Owner|\n",
      "|  85.5|    16.8|    Owner|\n",
      "|  64.8|    21.6|    Owner|\n",
      "|  61.5|    20.8|    Owner|\n",
      "|  87.0|    23.6|    Owner|\n",
      "+------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select * from rmowers_df').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min_income|\n",
      "+----------+\n",
      "|      33.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select min(Income) min_income from rmowers_df').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+\n",
      "|Income|Lot_Size|Ownership|\n",
      "+------+--------+---------+\n",
      "|  33.0|    18.8| Nonowner|\n",
      "+------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from rmowers_df where Income in (select min(Income) min_income from rmowers_df)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster('local[*]').setAppName('first-ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x114f55250>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota = pd.read_csv('/Users/tjmask/Desktop/Semester2/Spark/PySpark/Datasets/ToyotaCorolla.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Model</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>...</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Parking_Assistant</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                          Model  Price  Age_08_04  \\\n",
       "0   1  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13500         23   \n",
       "1   2  TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13750         23   \n",
       "\n",
       "   Mfg_Month  Mfg_Year     KM Fuel_Type  HP  Met_Color  ... Powered_Windows  \\\n",
       "0         10      2002  46986    Diesel  90          1  ...               1   \n",
       "1         10      2002  72937    Diesel  90          1  ...               0   \n",
       "\n",
       "   Power_Steering  Radio  Mistlamps  Sport_Model  Backseat_Divider  \\\n",
       "0               1      0          0            0                 1   \n",
       "1               1      0          0            0                 1   \n",
       "\n",
       "   Metallic_Rim  Radio_cassette  Parking_Assistant  Tow_Bar  \n",
       "0             0               0                  0        0  \n",
       "1             0               0                  0        0  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyota.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1436, 39)\n"
     ]
    }
   ],
   "source": [
    "print(toyota.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "5       0\n",
       "6       0\n",
       "7       0\n",
       "8       0\n",
       "9       0\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      0\n",
       "14      0\n",
       "15      0\n",
       "16      0\n",
       "17      1\n",
       "18      0\n",
       "19      0\n",
       "20      1\n",
       "21      0\n",
       "22      1\n",
       "23      0\n",
       "24      0\n",
       "25      1\n",
       "26      0\n",
       "27      0\n",
       "28      0\n",
       "29      0\n",
       "       ..\n",
       "1406    0\n",
       "1407    1\n",
       "1408    0\n",
       "1409    1\n",
       "1410    0\n",
       "1411    0\n",
       "1412    0\n",
       "1413    1\n",
       "1414    1\n",
       "1415    0\n",
       "1416    0\n",
       "1417    0\n",
       "1418    0\n",
       "1419    0\n",
       "1420    0\n",
       "1421    0\n",
       "1422    0\n",
       "1423    0\n",
       "1424    0\n",
       "1425    0\n",
       "1426    1\n",
       "1427    0\n",
       "1428    0\n",
       "1429    1\n",
       "1430    0\n",
       "1431    0\n",
       "1432    0\n",
       "1433    0\n",
       "1434    0\n",
       "1435    0\n",
       "Name: Tow_Bar, Length: 1436, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyota_new = toyota.drop(columns =['Id', 'Model', 'Fuel_Type', 'Color']).dropna()\n",
    "toyota_new.iloc[:, 34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_new.to_csv('/Users/tjmask/Desktop/Semester2/Spark/PySpark/Datasets/toyota_new.txt', sep=\",\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = sc.textFile('file:///Users/tjmask/Desktop/Semester2/Spark/PySpark/Datasets/toyota_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13500,23,10,2002,46986,90,1,0,2000,3,4,5,210,1165,0,1,3,1,1,1,0,0,1,0,1,1,1,0,0,0,1,0,0,0,0']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_point(line):\n",
    "    values = [s for s in line.strip().split(',')]\n",
    "    return LabeledPoint(values[34], values[0:33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [13500.0,23.0,10.0,2002.0,46986.0,90.0,1.0,0.0,2000.0,3.0,4.0,5.0,210.0,1165.0,0.0,1.0,3.0,1.0,1.0,1.0,0.0,0.0,1.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [13750.0,23.0,10.0,2002.0,72937.0,90.0,1.0,0.0,2000.0,3.0,4.0,5.0,210.0,1165.0,0.0,1.0,3.0,1.0,1.0,1.0,1.0,0.0,1.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [13950.0,24.0,9.0,2002.0,41711.0,90.0,1.0,0.0,2000.0,3.0,4.0,5.0,210.0,1165.0,1.0,1.0,3.0,1.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [14950.0,26.0,7.0,2002.0,48000.0,90.0,0.0,0.0,2000.0,3.0,4.0,5.0,210.0,1165.0,1.0,1.0,3.0,1.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [13750.0,30.0,3.0,2002.0,38500.0,90.0,0.0,0.0,2000.0,3.0,4.0,5.0,210.0,1170.0,1.0,1.0,3.0,1.0,1.0,1.0,1.0,0.0,1.0,0.0,1.0,1.0,1.0,0.0,1.0,0.0,1.0,0.0,0.0])]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parsed = points.map(parse_point)\n",
    "data_parsed.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_parsed.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = DecisionTree.trainClassifier(train, numClasses=5, categoricalFeaturesInfo= {}, maxDepth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = train_model.predict(test.map(lambda x: x.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (0.0, 0.0)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelsAndPrediction = test.map(lambda x: x.label).zip(predictions)\n",
    "LabelsAndPrediction.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testErr = LabelsAndPrediction.map(lambda x: x.keys()=x.values()).count()/(predictions.count())\n",
    "# # testErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = LabelsAndPrediction.keys().collect()\n",
    "values = LabelsAndPrediction.values().collect()\n",
    "count=0\n",
    "for i in range(410):\n",
    "    if keys[i] == values[i]:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2804878048780488"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testErr = 1 - count/(predictions.count())\n",
    "testErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 3 with 7 nodes\n",
      "  If (feature 1 <= 31.5)\n",
      "   If (feature 4 <= 33403.0)\n",
      "    Predict: 0.0\n",
      "   Else (feature 4 > 33403.0)\n",
      "    If (feature 27 <= 0.5)\n",
      "     Predict: 0.0\n",
      "    Else (feature 27 > 0.5)\n",
      "     Predict: 1.0\n",
      "  Else (feature 1 > 31.5)\n",
      "   Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelsAndPrediction.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 3), ('c', 2), ('a', 1), ('d', 2), ('b', 1), ('d', 3)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key = sc.parallelize([('a', 1),('b', 3),('c', 2),('a', 1),('d', 2),('b', 1),('d', 3)],4)\n",
    "# data_key.reduceByKey(lambda x, y: x + y).collect()\n",
    "data_key.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', False), ('c', 2), ('a', True), ('d', False)]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key.reduceByKey(lambda x, y: x==y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[281] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelsAndPrediction.filter(lambda x, y: x==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(LabelsAndPrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
